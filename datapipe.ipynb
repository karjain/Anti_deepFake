{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datapipe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karjain/Anti_deepFake/blob/main/datapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKaf32ElU_u1"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from os.path import join\n",
        "import cv2\n",
        "import dlib\n",
        "import glob\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJxq67LDczH",
        "outputId": "95ae7c69-5809-47e9-fde8-786a3e6a666c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wspWpMzWe3NF"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The following function picks up frames from the video and detects face in it. If a face is found, it is cropped and stored in the REAL or FAKE folder according to the videos label.\n",
        "\n",
        "The labels are dected from the metafile\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sh-3uOFe8hD"
      },
      "source": [
        "def video_to_croped_frames(video_files_root, out_path, metafile_path, frame_rate=33):\n",
        "  file_extensions = ['mp4','gif','webm','avi','3gp','wmv','flv','mkv']\n",
        "  #file_extension eg 'mp4', 'avi' \n",
        "  \n",
        "  #Read labels from a meta files\n",
        "  df = pd.read_json(metafile_path, orient='index')\n",
        "\n",
        "  video_files_path=[]\n",
        "  for ext in file_extensions:\n",
        "    video_files_path.extend(glob.glob(video_files_root + '/*.'+ext))\n",
        "    print(type(video_files_path))\n",
        "  no_files = len(video_files_path)\n",
        "\n",
        "  #os.makedirs(out_path+'/fake', exist_ok=True)\n",
        "  #os.makedirs(out_path+'/real', exist_ok=True)\n",
        "  \n",
        "  videos_processed=0\n",
        "\n",
        "  for video_file in video_files_path:\n",
        "    reader = cv2.VideoCapture(video_file)\n",
        "    \n",
        "    video_name = video_file.split('/')[-1]\n",
        "    video_fn = video_name.split('.')[0]\n",
        "\n",
        "    label = df.loc[video_name,'label']\n",
        "\n",
        "    #fps = reader.get(cv2.CAP_PROP_FPS)\n",
        "    #num_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    #print(\"num of frames: \",num_frames)\n",
        "  \n",
        "    # Face detector\n",
        "    face_detector = dlib.get_frontal_face_detector()\n",
        "    \n",
        "    # Frame numbers and length of output video\n",
        "    i=0\n",
        "    c=1\n",
        "    while reader.isOpened():\n",
        "        _, image = reader.read()\n",
        "        if image is None:\n",
        "            break\n",
        "        if c%frame_rate==0:\n",
        "    \n",
        "          # Image size\n",
        "          height, width = image.shape[:2]\n",
        "\n",
        "          # . Detect with dlib\n",
        "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "          faces = face_detector(gray, 1)\n",
        "          if len(faces):\n",
        "              for face in faces:\n",
        "                # Face crop with dlib and bounding box scale enlargement\n",
        "                x, y, size = get_boundingbox(face, width, height)\n",
        "                cropped_face = image[y:y+size, x:x+size]\n",
        "                cropped_face = cv2.resize(cropped_face, (112, 112))\n",
        "                if( label=='FAKE' ):\n",
        "                  cv2.imwrite(out_path + \"/fake/\" + \"deepF\" + video_fn+str(i) + '.jpg', cropped_face)\n",
        "                else:\n",
        "                  cv2.imwrite(out_path + \"/real/\" + \"deepF\" + video_fn+str(i) + '.jpg', cropped_face)\n",
        "                \n",
        "                i+=1\n",
        "                #cv2.waitKey(33)\n",
        "          \n",
        "        c+=1\n",
        "    print(video_name, \" \", label)\n",
        "    print(\"total frames written: \",i)\n",
        "    videos_processed+=1\n",
        "    print(\"Progress= \", (videos_processed/no_files)*100  )\n",
        "      \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN2r-IWbe-wu"
      },
      "source": [
        "video_to_croped_frames('/content/drive/MyDrive/Fake_dect/deepF/train_vid', '/content/drive/MyDrive/Fake_dect/merged_data', '/content/drive/MyDrive/Fake_dect/deepF/train_vid/metadata.json', frame_rate=33)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}