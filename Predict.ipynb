{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6G7dUOXBtf2lFITTFOFQ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karjain/Anti_deepFake/blob/main/Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeQIc8QVNjkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031d0a3a-da96-4c0b-d63f-5d9e80a6a4e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "%cd /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqIrA5E2OpaP"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "from tensorflow import keras\n",
        "import PIL.Image as Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkDLBBpqO5Wc"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Fake_dect/modelK.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiOBU45oaItx"
      },
      "source": [
        "def get_boundingbox(face, width, height, scale=1.3, minsize=None):\n",
        "    \"\"\"\n",
        "    Expects a dlib face to generate a quadratic bounding box.\n",
        "    :param face: dlib face class\n",
        "    :param width: frame width\n",
        "    :param height: frame height\n",
        "    :param scale: bounding box size multiplier to get a bigger face region\n",
        "    :param minsize: set minimum bounding box size\n",
        "    :return: x, y, bounding_box_size in opencv form\n",
        "    \"\"\"\n",
        "    x1 = face.left()\n",
        "    y1 = face.top()\n",
        "    x2 = face.right()\n",
        "    y2 = face.bottom()\n",
        "    size_bb = int(max(x2 - x1, y2 - y1) * scale)\n",
        "    if minsize:\n",
        "        if size_bb < minsize:\n",
        "            size_bb = minsize\n",
        "    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "    # Check for out of bounds, x-y top left corner\n",
        "    x1 = max(int(center_x - size_bb // 2), 0)\n",
        "    y1 = max(int(center_y - size_bb // 2), 0)\n",
        "    # Check for too big bb size for given x, y\n",
        "    size_bb = min(width - x1, size_bb)\n",
        "    size_bb = min(height - y1, size_bb)\n",
        "\n",
        "    return x1, y1, size_bb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evv6AyE_b3ne"
      },
      "source": [
        "def predict_face(model, video_files_path, frame_rate=33 ):\n",
        "    \n",
        "  frames=[]\n",
        "  prediction_list = []\n",
        "  confidence_list = []\n",
        "  final_pred=0\n",
        "  frames_with_faces = []\n",
        "  cropped_faces_list = []\n",
        "\n",
        "  video_file_name = video_files_path.split('/')[-1]\n",
        "  video_file_name_only = video_file_name.split('.')[0]\n",
        "\n",
        "  reader = cv2.VideoCapture(video_files_path)\n",
        "  \n",
        "  # Face detector\n",
        "  face_detector = dlib.get_frontal_face_detector()\n",
        "  \n",
        "  # Frame numbers and length of output video\n",
        "  i=0\n",
        "  c=1\n",
        "  while reader.isOpened():\n",
        "      _, image = reader.read()\n",
        "      if image is None:\n",
        "          #print('frame')\n",
        "          break\n",
        "      if c%frame_rate==1:\n",
        "        frames.append(image)\n",
        "  \n",
        "        # Image size\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        # . Detect with dlib\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        faces = face_detector(gray)\n",
        "        #If image with face found\n",
        "        if len(faces):\n",
        "            for face in faces:\n",
        "\n",
        "              image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "              frames_with_faces.append(image)\n",
        "\n",
        "              # Face crop with dlib and bounding box scale enlargement\n",
        "              x, y, size = get_boundingbox(face, width, height)\n",
        "              cropped_face = image[y:y+size, x:x+size]\n",
        "              cropped_faces_list.append(cropped_face)\n",
        "              \n",
        "              #Code to save imgaes with faces(optional)\n",
        "              # img = pImage.fromarray(image, 'RGB')\n",
        "              # image_name = video_file_name_only+\"_preprocessed_\"+str(i)+'.png'\n",
        "              # image_path = os.path.join(settings.PROJECT_DIR, 'uploaded_images', image_name)\n",
        "              # img.save(image_path)    \n",
        "\n",
        "              #Code to save cropped image(optional)\n",
        "              # img = pImage.fromarray(cropped_face, 'RGB')\n",
        "              # image_name = video_file_name_only+\"_cropped_faces_\"+str(i)+'.png'\n",
        "              # image_path = os.path.join(settings.PROJECT_DIR, 'uploaded_images', image_name)\n",
        "              # img.save(image_path)\n",
        "              \n",
        "              #Resize to models trained image size\n",
        "              cropped_face = cv2.resize(cropped_face,(224,224))\n",
        "              \n",
        "              #Normalize image before feeding it into model\n",
        "              norm_image = cv2.normalize(cropped_face, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "              input_arr = keras.preprocessing.image.img_to_array(norm_image)\n",
        "              input_arr = np.array([input_arr])\n",
        "              prediction = model.predict(input_arr)\n",
        "              prediction_list.append(prediction[0][0])\n",
        "              confidence_list.append(round(prediction[0][0], 1))\n",
        "              i+=1\n",
        "        else:\n",
        "          print(\"No Face found\")\n",
        "          break\n",
        "      c+=1\n",
        "  reader.release()           \n",
        "        \n",
        "  print(\"prediction_list\",prediction_list)\n",
        "  confidence = np.mean(prediction_list)\n",
        "  prediction_list = [round(pred,1) for pred in prediction_list]\n",
        "\n",
        "  if np.sum(confidence) > 0.9:\n",
        "    final_pred = \"REAL\"\n",
        "  else:\n",
        "    final_pred = \"FAKE\"\n",
        "  \n",
        "  print(\"final \", final_pred)\n",
        "  return final_pred, frames_with_faces, cropped_faces_list, confidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaWITnmib57i"
      },
      "source": [
        "final_pred, frames_with_faces, cropped_faces_list, confidence = predict_face(reload_model,'/content/drive/MyDrive/Fake_dect/test_videos/real/aelfnikyqj.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}