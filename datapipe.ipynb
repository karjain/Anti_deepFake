{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datapipe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karjain/Anti_deepFake/blob/main/datapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKaf32ElU_u1"
      },
      "source": [
        "import os\r\n",
        "import argparse\r\n",
        "from os.path import join\r\n",
        "import cv2\r\n",
        "import dlib\r\n",
        "import glob\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJxq67LDczH",
        "outputId": "95ae7c69-5809-47e9-fde8-786a3e6a666c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "VCYbABwT6IuG",
        "outputId": "e4ef9938-b765-4e2c-eaba-5f83f42e8bf9"
      },
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/Fake_dect/deepF/train_vid/metadata.json'\r\n",
        "                  ,orient='index').reset_index()\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aagfhgtpmv.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>vudstovrck.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aapnvogymq.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>jdubbvfswz.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abarnvbtwb.mp4</td>\n",
              "      <td>REAL</td>\n",
              "      <td>train</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abofeumbvv.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>atvmxvwyns.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abqwwspghj.mp4</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>qzimuostzz.mp4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            index label  split        original\n",
              "0  aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
              "1  aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
              "2  abarnvbtwb.mp4  REAL  train            None\n",
              "3  abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
              "4  abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TMaWmIddRIi"
      },
      "source": [
        "import glob\r\n",
        "\r\n",
        "video_files_path =  glob.glob('/content/drive/MyDrive/Fake_dect/deepF/train_vid/*.mp4')\r\n",
        "no_files=len(video_files_path)\r\n",
        "processed=0\r\n",
        "for video_file in video_files_path:\r\n",
        "  \r\n",
        "  reader = cv2.VideoCapture(video_file)\r\n",
        "  video_fn = video_file.split('/')[-1].split('.')[0]\r\n",
        "  video_name=video_fn+\".mp4\"\r\n",
        "  label = df.loc[df['index']==video_name,'label'].item()\r\n",
        "\r\n",
        "  #print(video_fn)\r\n",
        "\r\n",
        "  i=0\r\n",
        "  #os.makedirs(output_path, exist_ok=True)\r\n",
        "\r\n",
        "  fps = reader.get(cv2.CAP_PROP_FPS)\r\n",
        "  num_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\r\n",
        "  #print(\"num of frames: \",num_frames)\r\n",
        " \r\n",
        "  # Face detector\r\n",
        "  face_detector = dlib.get_frontal_face_detector()\r\n",
        " \r\n",
        "  # Text variables\r\n",
        "  #font_face = cv2.FONT_HERSHEY_SIMPLEX\r\n",
        " \r\n",
        "  # Frame numbers and length of output video\r\n",
        "  frame_num = 0\r\n",
        "  c=1\r\n",
        "  while reader.isOpened():\r\n",
        "      _, image = reader.read()\r\n",
        "      if image is None:\r\n",
        "          break\r\n",
        "      if c%33==0:\r\n",
        "        frame_num += 1\r\n",
        "  \r\n",
        "        # Image size\r\n",
        "        height, width = image.shape[:2]\r\n",
        "  \r\n",
        "  \r\n",
        "        # . Detect with dlib\r\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "        faces = face_detector(gray, 1)\r\n",
        "        if len(faces):\r\n",
        "            # For now only take biggest face\r\n",
        "            for face in faces:\r\n",
        "              # Face crop with dlib and bounding box scale enlargement\r\n",
        "              x, y, size = get_boundingbox(face, width, height)\r\n",
        "              cropped_face = image[y:y+size, x:x+size]\r\n",
        "              if( label=='FAKE' ):\r\n",
        "                cv2.imwrite(\"/content/drive/MyDrive/Fake_dect/deepF/train_img/fake/\"+video_fn+str(i)+'.jpg',cropped_face)\r\n",
        "              else:\r\n",
        "                cv2.imwrite(\"/content/drive/MyDrive/Fake_dect/deepF/train_img/real/\"+video_fn+str(i)+'.jpg',cropped_face)\r\n",
        "              \r\n",
        "              i+=1\r\n",
        "              #cv2.waitKey(33)\r\n",
        "        \r\n",
        "      c+=1\r\n",
        "  print(video_name, \" \", label)\r\n",
        "  print(\"total frames taken: \",frame_num)\r\n",
        "  processed+=1\r\n",
        "  print(\"Progress= \", (processed/no_files)*100  )\r\n",
        "      \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1BWNnctuktD"
      },
      "source": [
        "###Functions\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjNCN6zhzFuX"
      },
      "source": [
        "def get_boundingbox(face, width, height, scale=1.3, minsize=None):\r\n",
        "    \"\"\"\r\n",
        "    Expects a dlib face to generate a quadratic bounding box.\r\n",
        "    :param face: dlib face class\r\n",
        "    :param width: frame width\r\n",
        "    :param height: frame height\r\n",
        "    :param scale: bounding box size multiplier to get a bigger face region\r\n",
        "    :param minsize: set minimum bounding box size\r\n",
        "    :return: x, y, bounding_box_size in opencv form\r\n",
        "    \"\"\"\r\n",
        "    x1 = face.left()\r\n",
        "    y1 = face.top()\r\n",
        "    x2 = face.right()\r\n",
        "    y2 = face.bottom()\r\n",
        "    size_bb = int(max(x2 - x1, y2 - y1) * scale)\r\n",
        "    if minsize:\r\n",
        "        if size_bb < minsize:\r\n",
        "            size_bb = minsize\r\n",
        "    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\r\n",
        "\r\n",
        "    # Check for out of bounds, x-y top left corner\r\n",
        "    x1 = max(int(center_x - size_bb // 2), 0)\r\n",
        "    y1 = max(int(center_y - size_bb // 2), 0)\r\n",
        "    # Check for too big bb size for given x, y\r\n",
        "    size_bb = min(width - x1, size_bb)\r\n",
        "    size_bb = min(height - y1, size_bb)\r\n",
        "\r\n",
        "    return x1, y1, size_bb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKped_s3unJ4"
      },
      "source": [
        "def video_to_croped_frames(video_files_root, out_path, metafile_path, frame_rate=33):\r\n",
        "  file_extensions = ['mp4','avi']\r\n",
        "  #file_extension eg 'mp4', 'avi' \r\n",
        "  \r\n",
        "  df = pd.read_json(metafile_path, orient='index')                \r\n",
        "  video_files_path=[]\r\n",
        "  for ext in file_extensions:\r\n",
        "    video_files_path.extend(glob.glob(video_files_root + '/*.'+ext))\r\n",
        "    print(type(video_files_path))\r\n",
        "  no_files = len(video_files_path)\r\n",
        "\r\n",
        "  os.makedirs(output_path+'/fake', exist_ok=True)\r\n",
        "  os.makedirs(output_path+'/real', exist_ok=True)\r\n",
        "  \r\n",
        "  videos_processed=0\r\n",
        "\r\n",
        "  for video_file in video_files_path:\r\n",
        "    reader = cv2.VideoCapture(video_file)\r\n",
        "    \r\n",
        "    video_name = video_file.split('/')[-1]\r\n",
        "    video_fn = video_name.split('.')[0]\r\n",
        "\r\n",
        "    label = df.loc[video_name,'label']\r\n",
        "\r\n",
        "    #fps = reader.get(cv2.CAP_PROP_FPS)\r\n",
        "    #num_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\r\n",
        "    #print(\"num of frames: \",num_frames)\r\n",
        "  \r\n",
        "    # Face detector\r\n",
        "    face_detector = dlib.get_frontal_face_detector()\r\n",
        "    \r\n",
        "    # Frame numbers and length of output video\r\n",
        "    i=0\r\n",
        "    c=1\r\n",
        "    while reader.isOpened():\r\n",
        "        _, image = reader.read()\r\n",
        "        if image is None:\r\n",
        "            break\r\n",
        "        if c%frame_rate==0:\r\n",
        "    \r\n",
        "          # Image size\r\n",
        "          height, width = image.shape[:2]\r\n",
        "\r\n",
        "          # . Detect with dlib\r\n",
        "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "          faces = face_detector(gray, 1)\r\n",
        "          if len(faces):\r\n",
        "              for face in faces:\r\n",
        "                # Face crop with dlib and bounding box scale enlargement\r\n",
        "                x, y, size = get_boundingbox(face, width, height)\r\n",
        "                cropped_face = image[y:y+size, x:x+size]\r\n",
        "                if( label=='FAKE' ):\r\n",
        "                  cv2.imwrite(out_path + \"/fake/\" + video_fn+str(i) + '.jpg', cropped_face)\r\n",
        "                else:\r\n",
        "                  cv2.imwrite(out_path + \"/real/\" + video_fn+str(i) + '.jpg', cropped_face)\r\n",
        "                \r\n",
        "                i+=1\r\n",
        "                #cv2.waitKey(33)\r\n",
        "          \r\n",
        "        c+=1\r\n",
        "    print(video_name, \" \", label)\r\n",
        "    print(\"total frames written: \",i)\r\n",
        "    videos_processed+=1\r\n",
        "    print(\"Progress= \", (videos_processed/no_files)*100  )\r\n",
        "      \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n533IGLh8XH",
        "outputId": "39857c03-1153-4a47-b803-013e044d9d64"
      },
      "source": [
        "video_to_croped_frames('/content/drive/MyDrive/Fake_dect/deepF/train_vid', '/content/drive/MyDrive/Fake_dect/deepF', '/content/drive/MyDrive/Fake_dect/deepF/train_vid/metadata.json', frame_rate=33)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "aagfhgtpmv.mp4   FAKE\n",
            "total frames written:  9\n",
            "Progress=  0.25\n",
            "aapnvogymq.mp4   FAKE\n",
            "total frames written:  14\n",
            "Progress=  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpP_2hUs2vgw"
      },
      "source": [
        "#!rm /content/drive/MyDrive/Fake_dect/deepF/train_img/fake/*\r\n",
        "#!rm /content/drive/MyDrive/Fake_dect/deepF/train_img/real/*\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D0jCjeCXEqd"
      },
      "source": [
        "###**Fake** rename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-1SCvrNcleS"
      },
      "source": [
        "import os\r\n",
        "x=1 \r\n",
        "root = \"/content/drive/MyDrive/Fake_dect/trail\"\r\n",
        "for count, filename in enumerate(os.listdir(root)): \r\n",
        "        print(filename)\r\n",
        "\r\n",
        "        dst =\"/face\" + str(x) + \".jpg\"\r\n",
        "        src =root+ '/'+filename \r\n",
        "        \r\n",
        "        dst ='/content/drive/MyDrive/Fake_dect/renamed/face' + str(x) + '.jpg'\r\n",
        "        os.rename(src, dst)\r\n",
        "        x+=1 \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sqfO2fyXGxS"
      },
      "source": [
        "###Real rename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsq-azizvN7X"
      },
      "source": [
        "count=0\r\n",
        "for x in range(1,20000):\r\n",
        "  src = '/content/drive/MyDrive/Fake_dect/train_img/Real/' + str(x) + '.jpg'\r\n",
        "  if(os.path.exists(src)):\r\n",
        "    #dst = '/content/drive/MyDrive/Fake_dect/train_img/Real_renamed/' + 'face' + str(x) + '.jpg'\r\n",
        "    #os.rename(src, dst)\r\n",
        "    count+=1\r\n",
        "    print(count)\r\n",
        "print(\"count\",count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paf_VuDw3Dsn"
      },
      "source": [
        "!rm '/content/drive/MyDrive/Fake_dect/train_img/Real_renamed/'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}